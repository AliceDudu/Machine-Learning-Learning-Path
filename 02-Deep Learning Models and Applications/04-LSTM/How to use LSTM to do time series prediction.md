ç”¨ LSTM åšæ—¶é—´åºåˆ—é¢„æµ‹çš„ä¸€ä¸ªå°ä¾‹å­

é—®é¢˜ï¼šèˆªç­ä¹˜å®¢é¢„æµ‹
æ•°æ®ï¼š1949 åˆ° 1960 ä¸€å…± 12 å¹´ï¼Œæ¯å¹´ 12 ä¸ªæœˆçš„æ•°æ®ï¼Œä¸€å…± 144 ä¸ªæ•°æ®ï¼Œå•ä½æ˜¯ 1000
[ä¸‹è½½åœ°å€](https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line)
ç›®æ ‡ï¼šé¢„æµ‹å›½é™…èˆªç­æœªæ¥ 1 ä¸ªæœˆçš„ä¹˜å®¢æ•°

```python
import numpy
import matplotlib.pyplot as plt
from pandas import read_csv
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
%matplotlib inline
```

**å¯¼å…¥æ•°æ®ï¼š**

```python
# load the dataset
dataframe = read_csv('international-airline-passengers.csv', usecols=[1], engine='python', skipfooter=3)
dataset = dataframe.values
# å°†æ•´å‹å˜ä¸ºfloat
dataset = dataset.astype('float32')

plt.plot(dataset)
plt.show()
```

ä»è¿™ 12 å¹´çš„æ•°æ®å¯ä»¥çœ‹åˆ°ä¸Šå‡çš„è¶‹åŠ¿ï¼Œæ¯ä¸€å¹´å†…çš„ 12 ä¸ªæœˆé‡Œåˆæœ‰å‘¨æœŸæ€§å­£èŠ‚æ€§çš„è§„å¾‹

![](http://upload-images.jianshu.io/upload_images/1667471-67cad20cda715361.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

**éœ€è¦æŠŠæ•°æ®åšä¸€ä¸‹è½¬åŒ–:**

å°†ä¸€åˆ—å˜æˆä¸¤åˆ—ï¼Œç¬¬ä¸€åˆ—æ˜¯ t æœˆçš„ä¹˜å®¢æ•°ï¼Œç¬¬äºŒåˆ—æ˜¯ t+1 åˆ—çš„ä¹˜å®¢æ•°ã€‚
look_back å°±æ˜¯é¢„æµ‹ä¸‹ä¸€æ­¥æ‰€éœ€è¦çš„ time stepsï¼š

timesteps å°±æ˜¯ LSTM è®¤ä¸ºæ¯ä¸ªè¾“å…¥æ•°æ®ä¸å‰å¤šå°‘ä¸ªé™†ç»­è¾“å…¥çš„æ•°æ®æœ‰è”ç³»ã€‚ä¾‹å¦‚å…·æœ‰è¿™æ ·ç”¨æ®µåºåˆ—æ•°æ® â€œâ€¦ABCDBCEDFâ€¦â€ï¼Œå½“ timesteps ä¸º 3 æ—¶ï¼Œåœ¨æ¨¡å‹é¢„æµ‹ä¸­å¦‚æœè¾“å…¥æ•°æ®ä¸ºâ€œDâ€ï¼Œé‚£ä¹ˆä¹‹å‰æ¥æ”¶çš„æ•°æ®å¦‚æœä¸ºâ€œBâ€å’Œâ€œCâ€åˆ™æ­¤æ—¶çš„é¢„æµ‹è¾“å‡ºä¸º B çš„æ¦‚ç‡æ›´å¤§ï¼Œä¹‹å‰æ¥æ”¶çš„æ•°æ®å¦‚æœä¸ºâ€œCâ€å’Œâ€œEâ€ï¼Œåˆ™æ­¤æ—¶çš„é¢„æµ‹è¾“å‡ºä¸º F çš„æ¦‚ç‡æ›´å¤§ã€‚

```python
# X is the number of passengers at a given time (t) and Y is the number of passengers at the next time (t + 1).

# convert an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-look_back-1):
		a = dataset[i:(i+look_back), 0]
		dataX.append(a)
		dataY.append(dataset[i + look_back, 0])
	return numpy.array(dataX), numpy.array(dataY)

# fix random seed for reproducibility
numpy.random.seed(7)
```

å½“æ¿€æ´»å‡½æ•°ä¸º sigmoid æˆ–è€… tanh æ—¶ï¼Œè¦æŠŠæ•°æ®æ­£åˆ™è¯ï¼Œæ­¤æ—¶ LSTM æ¯”è¾ƒæ•æ„Ÿ
**è®¾å®š 67% æ˜¯è®­ç»ƒæ•°æ®ï¼Œä½™ä¸‹çš„æ˜¯æµ‹è¯•æ•°æ®**

```python
# normalize the dataset
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)


# split into train and test sets
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
```

X=t and Y=t+1 æ—¶çš„æ•°æ®ï¼Œå¹¶ä¸”æ­¤æ—¶çš„ç»´åº¦ä¸º [samples, features] 

```python
# use this function to prepare the train and test datasets for modeling
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)
```

æŠ•å…¥åˆ° LSTM çš„ X éœ€è¦æœ‰è¿™æ ·çš„ç»“æ„ï¼š [samples, time steps, features]ï¼Œæ‰€ä»¥åšä¸€ä¸‹å˜æ¢

```python
# reshape input to be [samples, time steps, features]
trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
```

**å»ºç«‹ LSTM æ¨¡å‹ï¼š**
è¾“å…¥å±‚æœ‰ 1 ä¸ªinputï¼Œéšè—å±‚æœ‰ 4 ä¸ªç¥ç»å…ƒï¼Œè¾“å‡ºå±‚å°±æ˜¯é¢„æµ‹ä¸€ä¸ªå€¼ï¼Œæ¿€æ´»å‡½æ•°ç”¨ sigmoidï¼Œè¿­ä»£ 100 æ¬¡ï¼Œbatch size ä¸º 1

```python
# create and fit the LSTM network
model = Sequential()
model.add(LSTM(4, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)
```

Epoch 100/100
1s - loss: 0.0020

**é¢„æµ‹ï¼š**

```python
# make predictions
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
```

è®¡ç®—è¯¯å·®ä¹‹å‰è¦å…ˆæŠŠé¢„æµ‹æ•°æ®è½¬æ¢æˆåŒä¸€å•ä½

```python
# invert predictions
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])
```

**è®¡ç®— mean squared error**

```python
trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
print('Train Score: %.2f RMSE' % (trainScore))
testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
print('Test Score: %.2f RMSE' % (testScore))
```
Train Score: 22.92 RMSE
Test Score: 47.53 RMSE

ç”»å‡ºç»“æœï¼šè“è‰²ä¸ºåŸæ•°æ®ï¼Œç»¿è‰²ä¸ºè®­ç»ƒé›†çš„é¢„æµ‹å€¼ï¼Œçº¢è‰²ä¸ºæµ‹è¯•é›†çš„é¢„æµ‹å€¼

```python
# shift train predictions for plotting
trainPredictPlot = numpy.empty_like(dataset)
trainPredictPlot[:, :] = numpy.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

# shift test predictions for plotting
testPredictPlot = numpy.empty_like(dataset)
testPredictPlot[:, :] = numpy.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

# plot baseline and predictions
plt.plot(scaler.inverse_transform(dataset))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()
```

![](http://upload-images.jianshu.io/upload_images/1667471-ad841e1d55d95e5b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


ä¸Šé¢çš„ç»“æœå¹¶ä¸æ˜¯æœ€ä½³çš„ï¼Œåªæ˜¯ä¸¾ä¸€ä¸ªä¾‹å­æ¥çœ‹ LSTM æ˜¯å¦‚ä½•åšæ—¶é—´åºåˆ—çš„é¢„æµ‹çš„
å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼Œæœ€ç›´æ¥çš„ éšè—å±‚çš„ç¥ç»å…ƒä¸ªæ•°æ˜¯ä¸æ˜¯å˜ä¸º 128 æ›´å¥½å‘¢ï¼Œéšè—å±‚æ•°æ˜¯ä¸æ˜¯å¯ä»¥å˜æˆ 2 æˆ–è€…æ›´å¤šå‘¢ï¼Œtime steps å¦‚æœå˜æˆ 3 ä¼šä¸ä¼šå¥½ä¸€ç‚¹

å¦å¤–æ„Ÿå…´è¶£çš„ç­’å­å¯ä»¥æƒ³æƒ³ï¼ŒRNN åšæ—¶é—´åºåˆ—çš„é¢„æµ‹åˆ°åº•å¥½ä¸å¥½å‘¢ ğŸŒ

å‚è€ƒèµ„æ–™ï¼š
http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/

---

æ¨èé˜…è¯» [å†å²æŠ€æœ¯åšæ–‡é“¾æ¥æ±‡æ€»](http://www.jianshu.com/p/28f02bb59fe5)
http://www.jianshu.com/p/28f02bb59fe5
ä¹Ÿè®¸å¯ä»¥æ‰¾åˆ°ä½ æƒ³è¦çš„